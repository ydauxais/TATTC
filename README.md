# Towards Automation of Topic Taxonomy Construction

This repository contains the code and the data used for the submission 58 of IDA 22

## Data

### S2ORC

The S2ORC dataset used in this paper in the `20200705v1` version. 
Because even the parsed are too large to be stored on this repository, please refer to the [S2ORC repository](https://github.com/allenai/s2orc) to download the dataset. 

#### Pre-processing

To preprocess the S2ORC dataset, you can use the cells of the `Extract S2ORC data` section in the [s2orc_preprocess notebook](preprocess/s2orc_preprocess.ipynb) in the `preprocess` repository by modifying the filenames to your system. 
The folder of interest will remain `full/metadata` in the S2ORC folder hierarchy.  

It will generate you two files, the first one to represent the abstracts + titles of the paper and the second to represent their metadata. 

### Classifications

The original ACM classification can be found at [https://cran.r-project.org/web/classifications/ACM-2012.html](https://cran.r-project.org/web/classifications/ACM-2012.html) while the Europa classification can be found at [https://ec.europa.eu/research/participants/data/call/trees/portal_keyword_tree.json](https://ec.europa.eu/research/participants/data/call/trees/portal_keyword_tree.json). 

The preprocessed networkx graph pickles representing both classifications without the "X and Y" topics are found in the [data](data) folder. 

### Matrix generation

The topic subsumption matrix can be generated using the script [knowledge/subsumption.py](knowledge/subsumption.py). 

It's usage is `py subsumption.py --data [paper data] --topics [topic list] --out [path and prefix of the ouput]`. 

The `data` argument is for the file containing on each line the titles + abstracts and correspond to the file generated by S2ORC preprocess. 
The `topics` argument is for the file listing the different topics to use it corresponds to the ACM and Europa topic files or our generated topics that are in the `data/topics` folder. 
The output will generate two files, one with the suffix `_subsumption.pickle` containing the `Subsumption` object and one with the suffix `_vectorizer.pickle` containing the `CountVectorizer` used to process the abstracts. 

After that you can use the rest of the [s2orc_preprocess notebook](preprocess/s2orc_preprocess.ipynb) to generate the rest of the matrices. 

### Evaluation

The evaluation of the parameter optimization is done in the [optuna_evaluation notebook](evaluation/optuna_evaluation.ipynb). 
You will need to adapt the filenames for the pickles you generated for ACM and Europa. 
This evaluation also generate taxonomies from which the nodes are used for the random evaluation. 

The code used to run the experiments of TaxoGen can be found at their [GitHub](https://github.com/franticnerd/taxogen). 
The files to use for TaxoGen can be generated thanks to the [taxogen_preprocess notebook](preprocess/taxogen_preprocess.ipynb). 

`/!\` We got several issues while attempting to run TaxoGen that you may encounter to. 
To avoid them, create a folder `data` near their `code` folder. 
- In `data` create a folder with the same name as `corpusName` in `run.sh`. 
- In this new folder create a folder `init`, a folder `input` and a folder with the same name as `taxonName` in `run.sh`. 
- Copy the files (`doc_ids.txt`, `embeddings.txt`, `index.txt`, `keyword_cnt.txt`, `keywords.txt` and `papers.txt`) generated by the `taxogen_preprocess notebook` in the folder `input`. 
- Also copy `doc_ids.txt`, `embeddings.txt`, `index.txt`, `keyword_cnt.txt`, `keywords.txt` in the `taxonName` folder + duplicate `keywords.txt` as `seed_keywords.txt`. 
- Modify the `root_dir` variable in the `main` function in `main.py` to fit your folder and create a new function in paras.py referring to your files. 
- For our experiments we duplicated the `load_dblp_params_method` to keep their parameters. 
- Modify the `opt` variable after `if __name__ == '__main__':` in `main.py` to call your new function
- Compile `word2vec` in the `code` folder using `gcc word2vec.c -o word2vec -lm -pthread -O2 -Wall -funroll-loops -Wno-unused-result`
- Finally, you may need to replace the `python` occurrences in `run.sh` by `python2`

After running TaxoGen, you can convert the results to a networkx graph `hierarchy_nx.pickle` and the associated clusters `clusters.pickle` using `py taxogen_postprocess/taxonomy_to_network --folder [the taxonName folder]`. 
Then you can compare the extracted taxonomy using `py evaluation/taxogen_evaluation --standard_graph [the ACM or Europa networkx pickle] --graph hierarchy_nx.pickle --clusters clusters.pickle --out [your output path]` and obtain a csv file summarizing it. 
You can also you the `--random` argument to generate the results of a random taxonomy using the same topics. 

